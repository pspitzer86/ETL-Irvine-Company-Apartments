{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Project\n",
    "## Irvine Company Apartments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set environment\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, insert\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from config import password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that communicates with the browser\n",
    "# and scrapes the page\n",
    "def make_soup(url, browser, tag, class_name, find_all):\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    if find_all:\n",
    "        return soup.find_all(tag, class_= class_name)\n",
    "    else:\n",
    "        return soup.find(tag, class_= class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to SQL database\n",
    "engine = create_engine(f'postgresql://postgres:{password}@localhost:5432/ETL_IrvineCoApts_db')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create references to our tables\n",
    "Cities = Base.classes.cities\n",
    "Complex = Base.classes.complex\n",
    "Apartments = Base.classes.apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate a database session\n",
    "session = Session(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\kate_\\.wdm\\drivers\\chromedriver\\win32\\88.0.4324.96\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our base URL and derive location URL\n",
    "base_url = \"https://www.irvinecompanyapartments.com\"\n",
    "loc_url = base_url + \"/locations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty lists for cities and complexes\n",
    "complex_list = []\n",
    "city_list = []\n",
    "\n",
    "# scrape the locations page for all cities that have ICA complexes\n",
    "location_soup = make_soup(loc_url, browser, \"li\", \"submarket-listing-item__sub-market-list__item\", True)\n",
    "\n",
    "# loop through each one scraped\n",
    "for loc in location_soup:\n",
    "    \n",
    "    # pull out the relative path for the city page\n",
    "    city_path = loc.find(\"a\", class_=\"link\")[\"href\"]\n",
    "    # append city path to base URL\n",
    "    city_url = base_url + city_path\n",
    "    \n",
    "    # now scrape the city page for each complex in that city\n",
    "    complex_soup = make_soup(city_url, browser, \"div\", \"search-result-item-card__cta-container--bottom\", True)\n",
    "    \n",
    "    # loop through each one found\n",
    "    for loc in complex_soup:\n",
    "        # pull elements with an href tag\n",
    "        links = loc.find(\"a\", href=True)\n",
    "        if links:\n",
    "            # we found one, so pull out the URL\n",
    "            x = str(links).split('href=\"')\n",
    "            y = x[1].split(\" \")\n",
    "            complex_url = y[0].replace('\"', '')\n",
    "            \n",
    "\n",
    "            # scrape the complex page for the complex name\n",
    "            complex_soup = make_soup(complex_url, browser, \"h1\", \"sticky-header__title-heading\", False)\n",
    "\n",
    "            if complex_soup:\n",
    "                # found a complex name\n",
    "                complex_name = complex_soup.text\n",
    "                \n",
    "                # save the complex URL and complex name for later processing\n",
    "                complex_list.append([complex_url, complex_name])\n",
    "                \n",
    "                \n",
    "                # derive the contact page for the complex\n",
    "                contact_url = complex_url + \"#contact\"\n",
    "            \n",
    "                # look for the address of the complex\n",
    "                contact_addr = make_soup(contact_url, browser, \"div\", \"contactus-leasing-address\", False).text\n",
    "                complex_addr = contact_addr.split(\"\\n\")[1]\n",
    "                \n",
    "                # pull out the area/county and city name\n",
    "                addr_pieces = complex_url.split(\"/\")\n",
    "                area_name = addr_pieces[4].replace(\"-\", \" \").title()\n",
    "                city_name = addr_pieces[5].replace(\"-\", \" \").title()\n",
    "                \n",
    "                # San Diego gives us problems\n",
    "                if area_name == \"San Diego\":\n",
    "                    if city_name != \"Carlsbad\":\n",
    "                        city_name = area_name\n",
    "                        \n",
    "                        \n",
    "                # initialize city ID before we start checking the database\n",
    "                city_id = 0\n",
    "                \n",
    "                # check to see if we've checked the database for this city before\n",
    "                if city_name not in city_list:\n",
    "                    \n",
    "                    # new city name.  pull the city id from the database\n",
    "                    result = session.query(Cities.city_id).filter(Cities.city_name == city_name).first()\n",
    "                    if result is None:\n",
    "                        # not in the database yet, so insert\n",
    "                        new_city = Cities(city_name = city_name, population = 0, cost_of_living = 0, \\\n",
    "                                          median_income = 0, median_age = 0)\n",
    "                        session.add(new_city)\n",
    "        \n",
    "                    session.commit()\n",
    "                    # save the city name so we don't check again\n",
    "                    city_list.append(city_name)\n",
    "                \n",
    "                # we had a new city, so we haven't retrieved the id yet\n",
    "                if city_id == 0:\n",
    "                    result = session.query(Cities.city_id).filter(Cities.city_name == city_name).first()\n",
    "                    city_id = result[0]\n",
    "                    \n",
    "                # check database for existence of complex\n",
    "                result = session.query(Complex.complex_id).filter(Complex.complex_name == complex_name).first()\n",
    "                if result is None:\n",
    "                    # new complex, so insert\n",
    "                    new_complex = Complex(complex_name=complex_name, complex_address=complex_addr, complex_url=complex_url, city_id=city_id)\n",
    "                    session.add(new_complex)\n",
    "                    \n",
    "                    \n",
    "                session.commit()\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop through list of complexes and build URL for scraping\n",
    "# available units\n",
    "for complex_entry in complex_list:\n",
    "    \n",
    "    complex_url = complex_entry[0]\n",
    "    complex_name = complex_entry[1]\n",
    "    \n",
    "    # get complex id from database\n",
    "    result = session.query(Complex.complex_id).filter(Complex.complex_name == complex_name).first()\n",
    "    complex_id = result[0]\n",
    "\n",
    "    # derive URL for available units page for current complex\n",
    "    avail_url = complex_url.replace(\".html\", \"/availability.html#floor-plan-list\")\n",
    "    \n",
    "    # scrape availablity page\n",
    "    floor_plans = make_soup(avail_url, browser, \"div\", \"fapt-fp-list-item\", True)\n",
    "\n",
    "    # loop through each floor plan found\n",
    "    for plan in floor_plans:\n",
    "\n",
    "        # Error handling\n",
    "        try:\n",
    "            # collect floor plan level data\n",
    "            plan_name = plan.find('div', class_=\"fapt-fp-list-item__column--plan-name\").text\n",
    "            unit_type = plan.find('div', class_=\"fapt-fp-list-item__column--beds-baths\").text\n",
    "            start_price = plan.find('div', class_=\"fapt-fp-list-item__column--price\").text\n",
    "            sq_ft = plan.find('div', class_=\"fapt-fp-list-item__column--sqft\").text\n",
    "            \n",
    "            # remove symbols from price string and square footage strings\n",
    "            if start_price == \"Call for pricing\":\n",
    "                start_price = \"0\"\n",
    "            start_price = start_price.replace(\"$\", \"\")\n",
    "            start_price = start_price.replace(\",\", \"\")\n",
    "            \n",
    "        \n",
    "            # scrape all units listed\n",
    "            units = plan.find_all(\"div\", class_=\"fapt-fp-unit__table-row\")\n",
    "        \n",
    "            for unit in units:\n",
    "                # now scrape the attributes for each unit\n",
    "                unit_name = unit.find(\"span\", class_=\"fapt-fp-unit__unit-name-text\")\n",
    "\n",
    "                if unit_name:\n",
    "                    # default vacant to False\n",
    "                    vacant = False\n",
    "                    unit_id = unit_name.text\n",
    "                    terms = unit.find(\"div\", class_=\"fapt-fp-unit__column-inner--term\").text\n",
    "                    curr_price = unit.find(\"div\", class_=\"fapt-fp-unit__column-inner--price\").text\n",
    "                    avail_date = unit.find(\"div\", class_=\"fapt-fp-unit__column-inner--available\").span.text\n",
    "                    \n",
    "                    # remove symbols from current price                \n",
    "                    curr_price = curr_price.replace(\"$\", \"\")\n",
    "                    curr_price = curr_price.replace(\",\", \"\")\n",
    "                    \n",
    "                    # if either of our prices are still non-numeric, set to 0\n",
    "                    if curr_price.isnumeric() == False:\n",
    "                        curr_price = \"0\"\n",
    "                        \n",
    "                   \n",
    "                    # grab current date\n",
    "                    today = date.today()\n",
    "                    curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "                    list_start_date = curr_date\n",
    "                    \n",
    "                    # make sure the available date is a date, or\n",
    "                    # if the date is past, set unit to vacant\n",
    "                    if avail_date == \"Today\" or avail_date <= curr_date:\n",
    "                        avail_date = curr_date\n",
    "                        vacant = True\n",
    "                        \n",
    "                        \n",
    "                    # check database for existence of complex\n",
    "                    result = session.query(Apartments.apartment_id).filter(Apartments.complex_id == complex_id) \\\n",
    "                                                                    .filter(Apartments.unit_id == unit_id).first()\n",
    "                    if result is None:\n",
    "                        # new unit, so insert\n",
    "                        new_unit = Apartments(complex_id=complex_id, unit_id=unit_id, sq_ft=sq_ft, plan_name=plan_name, \\\n",
    "                                             apt_type=unit_type, start_price=int(start_price), vacant=vacant, \\\n",
    "                                             curr_price=int(curr_price), list_start_date=list_start_date, \\\n",
    "                                             available_date=avail_date, curr_date=curr_date)\n",
    "                        session.add(new_unit)\n",
    "                    else:\n",
    "                        # already exists, so update\n",
    "                        session.query(Apartments)\\\n",
    "                                .filter(Apartments.complex_id == complex_id)\\\n",
    "                                .filter(Apartments.unit_id == unit_id) \\\n",
    "                                .update({Apartments.curr_price: int(curr_price), Apartments.vacant: vacant, \\\n",
    "                                        Apartments.curr_date: curr_date})\n",
    "\n",
    "                        \n",
    "\n",
    "                    \n",
    "                # commit data to database  \n",
    "                session.commit()\n",
    "\n",
    "\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close session\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
